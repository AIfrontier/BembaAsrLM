{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ft_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "16yb2F2xuhY-IC6fsJZAYiDaW5jg-2z8V",
      "authorship_tag": "ABX9TyPbC4NhcnEJmK5GoQOi6VqJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csikasote/BembaASR/blob/main/notebooks/ft_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u4nM9zSJfRR"
      },
      "source": [
        "PHASE 1: INSTALL DEEPSPEECH AND ITS DEPENDANCIES FOR THE ACCOUSTIC MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvbgrvTMp0jB"
      },
      "source": [
        "from IPython.display import clear_output\r\n",
        "!rm -rf /content/sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kRPwtDnF0uB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06d3965-3b1c-424f-8358-d6ae380b8b42"
      },
      "source": [
        "# STEP 1: DOWNLOAD AND INSTALL GITHUB LFS \n",
        "%cd /content/\n",
        "!wget https://github.com/git-lfs/git-lfs/releases/download/v2.11.0/git-lfs-linux-amd64-v2.11.0.tar.gz\n",
        "!tar xvf /content/git-lfs-linux-amd64-v2.11.0.tar.gz -C /content\n",
        "clear_output()\n",
        "!sudo ./install.sh\n",
        "\n",
        "# remove some unwanted files after installation\n",
        "!rm -rf git-lfs-linux-amd64-v2.11.0.tar.gz\n",
        "!rm -rf /content/README.md\n",
        "!rm -rf /content/CHANGELOG.md\n",
        "!rm -rf /content/install.sh\n",
        "!rm -rf /content/git-lfs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Git LFS initialized.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL-JVWAIGLPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db58c0d3-42dd-43ed-a095-1070a0fcfc24"
      },
      "source": [
        "# STEP 2: DOWNLOAD AND INSTALL DEEPSPEECH V0.8.2\n",
        "%cd /content/\n",
        "!git lfs install\n",
        "!git clone https://github.com/mozilla/DeepSpeech\n",
        "%cd DeepSpeech/\n",
        "!git checkout -b v0.8.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Git LFS initialized.\n",
            "Cloning into 'DeepSpeech'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 23077 (delta 46), reused 62 (delta 28), pack-reused 22965\u001b[K\n",
            "Receiving objects: 100% (23077/23077), 49.09 MiB | 6.00 MiB/s, done.\n",
            "Resolving deltas: 100% (15859/15859), done.\n",
            "/content/DeepSpeech\n",
            "Switched to a new branch 'v0.8.2'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra_wTIFXGnM2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "8dde84b5-1700-4f54-9e56-4a2383759881"
      },
      "source": [
        "# STEP 3: DOWNLOAD AND INSTALL DEPENDENCIES\n",
        "%cd '/content/DeepSpeech'\n",
        "!pip3 install --upgrade pip==20.0.2 wheel==0.34.2 setuptools==46.1.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepSpeech\n",
            "Collecting pip==20.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 13.6MB/s \n",
            "\u001b[?25hCollecting wheel==0.34.2\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/23/848298cccf8e40f5bbb59009b32848a4c38f4e7f3364297ab3c3e2e2cd14/wheel-0.34.2-py2.py3-none-any.whl\n",
            "Collecting setuptools==46.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/df/635cdb901ee4a8a42ec68e480c49f85f4c59e8816effbf57d9e6ee8b3588/setuptools-46.1.3-py3-none-any.whl (582kB)\n",
            "\u001b[K     |████████████████████████████████| 583kB 58.6MB/s \n",
            "\u001b[31mERROR: tensorflow 2.4.0 has requirement wheel~=0.35, but you'll have wheel 0.34.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip, wheel, setuptools\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "  Found existing installation: wheel 0.36.2\n",
            "    Uninstalling wheel-0.36.2:\n",
            "      Successfully uninstalled wheel-0.36.2\n",
            "  Found existing installation: setuptools 51.0.0\n",
            "    Uninstalling setuptools-51.0.0:\n",
            "      Successfully uninstalled setuptools-51.0.0\n",
            "Successfully installed pip-20.0.2 setuptools-46.1.3 wheel-0.34.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSe4VRnSiJwm",
        "outputId": "59127f60-bea9-4088-a0f2-caa8e826bb9b"
      },
      "source": [
        "%cd '/content/DeepSpeech'\n",
        "!pip3 install --upgrade -e ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepSpeech\n",
            "Obtaining file:///content/DeepSpeech\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.10.0a3) (1.19.4)\n",
            "Requirement already satisfied, skipping upgrade: progressbar2 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.10.0a3) (3.38.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.10.0a3) (1.15.0)\n",
            "Collecting pyxdg\n",
            "  Downloading pyxdg-0.27-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting attrdict\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.10.0a3) (0.10.0)\n",
            "Collecting semver\n",
            "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting opuslib==2.0.0\n",
            "  Downloading opuslib-2.0.0.tar.gz (7.3 kB)\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.3.0.tar.gz (258 kB)\n",
            "\u001b[K     |████████████████████████████████| 258 kB 16.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sox\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied, skipping upgrade: bs4 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.10.0a3) (0.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.10.0a3) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.10.0a3) (2.23.0)\n",
            "Collecting numba==0.47.0\n",
            "  Downloading numba-0.47.0-cp36-cp36m-manylinux1_x86_64.whl (3.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 24.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: llvmlite==0.31.0 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.10.0a3) (0.31.0)\n",
            "Requirement already satisfied, skipping upgrade: librosa in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.10.0a3) (0.6.3)\n",
            "Collecting soundfile\n",
            "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
            "Collecting ds_ctcdecoder==0.10.0-alpha.3\n",
            "  Downloading ds_ctcdecoder-0.10.0a3-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 71.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.15.4\n",
            "  Downloading tensorflow-1.15.4-cp36-cp36m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 37 kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->deepspeech-training==0.10.0a3) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.10.0a3) (1.3.20)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-4.6.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting cmaes>=0.6.0\n",
            "  Downloading cmaes-0.7.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.10.0a3) (20.8)\n",
            "Requirement already satisfied, skipping upgrade: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.10.0a3) (1.4.1)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.5.0-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 12.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.10.0a3) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.10.0a3) (4.41.1)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.4.3-py2.py3-none-any.whl (159 kB)\n",
            "\u001b[K     |████████████████████████████████| 159 kB 72.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->deepspeech-training==0.10.0a3) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->deepspeech-training==0.10.0a3) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->deepspeech-training==0.10.0a3) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.10.0a3) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.10.0a3) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.10.0a3) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.10.0a3) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from numba==0.47.0->deepspeech-training==0.10.0a3) (46.1.3)\n",
            "Requirement already satisfied, skipping upgrade: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.10.0a3) (2.1.9)\n",
            "Requirement already satisfied, skipping upgrade: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.10.0a3) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.10.0a3) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.10.0a3) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile->deepspeech-training==0.10.0a3) (1.14.4)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 65.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (3.12.4)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (3.3.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 54.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->optuna->deepspeech-training==0.10.0a3) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna->deepspeech-training==0.10.0a3) (3.13)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.5.1-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 74.2 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting PrettyTable<0.8,>=0.7.2\n",
            "  Downloading prettytable-0.7.2.tar.bz2 (21 kB)\n",
            "Collecting cmd2!=0.8.3,>=0.8.0\n",
            "  Downloading cmd2-1.4.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 69.3 MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "  Downloading Mako-1.1.3-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile->deepspeech-training==0.10.0a3) (2.20)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->deepspeech-training==0.10.0a3) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->deepspeech-training==0.10.0a3) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4->deepspeech-training==0.10.0a3) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=1.7.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from stevedore>=2.0.1->cliff->optuna->deepspeech-training==0.10.0a3) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.10.0a3) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.1.tar.gz (20 kB)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.10.0a3) (20.3.0)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna->deepspeech-training==0.10.0a3) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=2.0.1->cliff->optuna->deepspeech-training==0.10.0a3) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=2.0.1->cliff->optuna->deepspeech-training==0.10.0a3) (3.7.4.3)\n",
            "Building wheels for collected packages: opuslib, optuna, gast, PrettyTable, pyperclip\n",
            "  Building wheel for opuslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opuslib: filename=opuslib-2.0.0-py3-none-any.whl size=11009 sha256=40c574b29329b6214d755fef0514b0e15046164f1626b89f4d0feff135ac77fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/01/88/37797e9e9d157a33eefed22a46aa0bf5044effcec6a9181e41\n",
            "  Building wheel for optuna (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.3.0-py3-none-any.whl size=359760 sha256=96164dd300105e3e9946d148175bed712156de0a6087db5d299f9252eb078652\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/a6/07/3e68f946721e5e7f15395097b477800eff26673717b5e50f5f\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=7ef68da3449166b5c24902963ba98ca756b034f03626145fb5801b33f383d9c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
            "  Building wheel for PrettyTable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PrettyTable: filename=prettytable-0.7.2-py3-none-any.whl size=13698 sha256=82b1664c5872d0a9fbd4500b2c06e0583bf8618f0596eea021bc052b945a208a\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/15/c3/5f28b42ae9c81638570b8b7ed654e0f98c5fdc08875869511b\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.1-py3-none-any.whl size=11118 sha256=7324aeb5307fd73558dd6cd098e43df976523c8b5c4cc340dc826dbbb01ee040\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/27/28/fa23ac551b4fad562edc8d50a4ae1182f31408aae1d6027c39\n",
            "Successfully built opuslib optuna gast PrettyTable pyperclip\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numba!=0.47,>=0.46, but you'll have numba 0.47.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.4 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyxdg, attrdict, semver, opuslib, colorlog, cmaes, pbr, stevedore, PrettyTable, pyperclip, colorama, cmd2, cliff, Mako, python-editor, alembic, optuna, sox, numba, soundfile, ds-ctcdecoder, tensorboard, keras-applications, gast, tensorflow-estimator, tensorflow, deepspeech-training\n",
            "  Attempting uninstall: PrettyTable\n",
            "    Found existing installation: prettytable 2.0.0\n",
            "    Uninstalling prettytable-2.0.0:\n",
            "      Successfully uninstalled prettytable-2.0.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.48.0\n",
            "    Uninstalling numba-0.48.0:\n",
            "      Successfully uninstalled numba-0.48.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.4.0\n",
            "    Uninstalling tensorflow-2.4.0:\n",
            "      Successfully uninstalled tensorflow-2.4.0\n",
            "  Running setup.py develop for deepspeech-training\n",
            "Successfully installed Mako-1.1.3 PrettyTable-0.7.2 alembic-1.4.3 attrdict-2.0.1 cliff-3.5.0 cmaes-0.7.0 cmd2-1.4.0 colorama-0.4.4 colorlog-4.6.2 deepspeech-training ds-ctcdecoder-0.10.0a3 gast-0.2.2 keras-applications-1.0.8 numba-0.47.0 optuna-2.3.0 opuslib-2.0.0 pbr-5.5.1 pyperclip-1.8.1 python-editor-1.0.4 pyxdg-0.27 semver-2.13.0 soundfile-0.10.3.post1 sox-1.4.1 stevedore-3.3.0 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CavPfB-vHCLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae4a989-fcfb-42ec-ad30-a60974c87838"
      },
      "source": [
        "# STEP 4: INSTALL REQUIRED TENSORFLOW VERSION = 'tensorflow-gpu==1.15.2'\n",
        "from IPython.display import clear_output\n",
        "!pip3 uninstall tensorflow\n",
        "!pip3 install 'tensorflow-gpu==1.15.2'\n",
        "#clear_output()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: tensorflow 1.15.4\n",
            "Uninstalling tensorflow-1.15.4:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/freeze_graph\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-1.15.4.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-1.15.4\n",
            "Collecting tensorflow-gpu==1.15.2\n",
            "  Downloading tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0 MB 33 kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.15.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.19.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.3.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (46.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.7.4.3)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MUPmOzGHufO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e47716b-87e1-424c-a75c-a89358e3159f"
      },
      "source": [
        "# STEP 5 INSTALL DEEPSPEECH-GPU\n",
        "!pip3 install deepspeech\n",
        "!pip3 install deepspeech-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepspeech\n",
            "  Downloading deepspeech-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (9.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2 MB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deepspeech) (1.19.4)\n",
            "Installing collected packages: deepspeech\n",
            "Successfully installed deepspeech-0.9.3\n",
            "Collecting deepspeech-gpu\n",
            "  Downloading deepspeech_gpu-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 146 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deepspeech-gpu) (1.19.4)\n",
            "Installing collected packages: deepspeech-gpu\n",
            "Successfully installed deepspeech-gpu-0.9.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kws-pC7HDoxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db593d9-67dc-4d7d-93f9-2949efe27369"
      },
      "source": [
        "# STEP 6: DOWNLOAD AND EXTRACT 'native_client.amd64.cuda.linux.tar.xz' \n",
        "!cd /content/DeepSpeech/data/lm/ && \\\n",
        "wget https://github.com/mozilla/DeepSpeech/releases/download/v0.8.2/native_client.amd64.cuda.linux.tar.xz && \\\n",
        "tar xvf native_client.amd64.cuda.linux.tar.xz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-04 18:27:41--  https://github.com/mozilla/DeepSpeech/releases/download/v0.8.2/native_client.amd64.cuda.linux.tar.xz\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/60273704/adcac680-e49c-11ea-949c-0c380912af4a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210104%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210104T182741Z&X-Amz-Expires=300&X-Amz-Signature=72bd1f057483bc3e4ef8b27ed2083b969284e710a7cefca9da6808078cc1ddba&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Dnative_client.amd64.cuda.linux.tar.xz&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-01-04 18:27:41--  https://github-production-release-asset-2e65be.s3.amazonaws.com/60273704/adcac680-e49c-11ea-949c-0c380912af4a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210104%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210104T182741Z&X-Amz-Expires=300&X-Amz-Signature=72bd1f057483bc3e4ef8b27ed2083b969284e710a7cefca9da6808078cc1ddba&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Dnative_client.amd64.cuda.linux.tar.xz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.96.212\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.96.212|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11347900 (11M) [application/octet-stream]\n",
            "Saving to: ‘native_client.amd64.cuda.linux.tar.xz’\n",
            "\n",
            "native_client.amd64 100%[===================>]  10.82M  12.6MB/s    in 0.9s    \n",
            "\n",
            "2021-01-04 18:27:43 (12.6 MB/s) - ‘native_client.amd64.cuda.linux.tar.xz’ saved [11347900/11347900]\n",
            "\n",
            "libdeepspeech.so\n",
            "generate_scorer_package\n",
            "LICENSE\n",
            "deepspeech\n",
            "deepspeech.h\n",
            "README.mozilla\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3JcUThNMcQz"
      },
      "source": [
        "# STEP 7: CHECK AND TEST THAT DEEPSPEECH IS INSTALLED AND WORKING AS REQUIRED\n",
        "#!python3 '/content/DeepSpeech/DeepSpeech.py' --helpfull\n",
        "#clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBqlRqyqRwr-"
      },
      "source": [
        "PHASE 2: MODEL FINETUNING THE DEEPSPEECH MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSpsNJQOkbrs",
        "outputId": "b1105139-928a-4af8-9c6b-6718dd5fc68a"
      },
      "source": [
        "# STEP 1: DOWNLOAD AND EXTRACT DEEPSPEECHV0.8.2 CHECKPOINTS\n",
        "%cd '/content/drive/MyDrive/deepspeech/finetune_model/checkpoint'\n",
        "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.8.2/deepspeech-0.8.2-checkpoint.tar.gz\n",
        "!tar xvfz deepspeech-0.8.2-checkpoint.tar.gz\n",
        "!rm -rf xvfz deepspeech-0.8.2-checkpoint.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/deepspeech/finetune_model/checkpoint\n",
            "--2021-01-04 18:29:50--  https://github.com/mozilla/DeepSpeech/releases/download/v0.8.2/deepspeech-0.8.2-checkpoint.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/60273704/61c85380-e495-11ea-9097-d20132b0460b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210104%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210104T182950Z&X-Amz-Expires=300&X-Amz-Signature=135077963f402c0867fb846200834df9fbf9cccda94f4ba399209eb73df6c5a1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.8.2-checkpoint.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-01-04 18:29:50--  https://github-production-release-asset-2e65be.s3.amazonaws.com/60273704/61c85380-e495-11ea-9097-d20132b0460b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210104%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210104T182950Z&X-Amz-Expires=300&X-Amz-Signature=135077963f402c0867fb846200834df9fbf9cccda94f4ba399209eb73df6c5a1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.8.2-checkpoint.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.16.76\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.16.76|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 644570497 (615M) [application/octet-stream]\n",
            "Saving to: ‘deepspeech-0.8.2-checkpoint.tar.gz’\n",
            "\n",
            "deepspeech-0.8.2-ch 100%[===================>] 614.71M  34.6MB/s    in 20s     \n",
            "\n",
            "2021-01-04 18:30:10 (31.3 MB/s) - ‘deepspeech-0.8.2-checkpoint.tar.gz’ saved [644570497/644570497]\n",
            "\n",
            "._deepspeech-0.8.2-checkpoint\n",
            "deepspeech-0.8.2-checkpoint/\n",
            "deepspeech-0.8.2-checkpoint/._checkpoint\n",
            "deepspeech-0.8.2-checkpoint/checkpoint\n",
            "deepspeech-0.8.2-checkpoint/._best_dev-732522.data-00000-of-00001\n",
            "deepspeech-0.8.2-checkpoint/best_dev-732522.data-00000-of-00001\n",
            "deepspeech-0.8.2-checkpoint/._best_dev-732522.index\n",
            "deepspeech-0.8.2-checkpoint/best_dev-732522.index\n",
            "deepspeech-0.8.2-checkpoint/._best_dev_checkpoint\n",
            "deepspeech-0.8.2-checkpoint/best_dev_checkpoint\n",
            "deepspeech-0.8.2-checkpoint/._best_dev-732522.meta\n",
            "deepspeech-0.8.2-checkpoint/best_dev-732522.meta\n",
            "deepspeech-0.8.2-checkpoint/._alphabet.txt\n",
            "deepspeech-0.8.2-checkpoint/alphabet.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRcEaw9VRSh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28641266-fbf8-49eb-d70e-7093994a5c64"
      },
      "source": [
        "# STEP 2: FINETUNE ACOUSTIC MODEL WITH DEEPSPEECHV0.8.2 (-LM)\n",
        "!python3 /content/DeepSpeech/DeepSpeech.py \\\n",
        "  --train_files /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/train.csv \\\n",
        "  --dev_files /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv \\\n",
        "  --test_files /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test.csv \\\n",
        "  --checkpoint_dir /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint \\\n",
        "  --alphabet_config_path /content/DeepSpeech/data/alphabet.txt \\\n",
        "  --export_dir /content/drive/MyDrive/deepspeech/finetune_model/export \\\n",
        "  --summary_dir /content/drive/MyDrive/deepspeech/finetune_model/summary \\\n",
        "  --learning_rate 0.00005 \\\n",
        "  --dropout_rate 0.4 \\\n",
        "  --train_batch_size 64 \\\n",
        "  --test_batch_size 32 \\\n",
        "  --dev_batch_size 32 \\\n",
        "  --train_cudnn True \\\n",
        "  --early_stop True \\\n",
        "  --n_hidden 2048 \\\n",
        "  --es_epochs 2 \\\n",
        "  --epochs 50 \\\n",
        "  --export_file_name 'ft_model' \\\n",
        "  --export_author_id 'csikasote' \\\n",
        "  --augment reverb[p=0.2,delay=50.0~30.0,decay=10.0:2.0~1.0] \\\n",
        "  --augment volume[p=0.2,dbfs=-10:-40] \\\n",
        "  --augment pitch[p=0.2,pitch=1~0.2] \\\n",
        "  --augment tempo[p=0.2,factor=1~0.5] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0104 18:35:23.754375 140701701326720 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-732522\n",
            "I Loading variable from checkpoint: beta1_power\n",
            "I Loading variable from checkpoint: beta2_power\n",
            "I Loading variable from checkpoint: cudnn_lstm/opaque_kernel\n",
            "I Loading variable from checkpoint: cudnn_lstm/opaque_kernel/Adam\n",
            "I Loading variable from checkpoint: cudnn_lstm/opaque_kernel/Adam_1\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/bias/Adam\n",
            "I Loading variable from checkpoint: layer_6/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "I Loading variable from checkpoint: layer_6/weights/Adam\n",
            "I Loading variable from checkpoint: layer_6/weights/Adam_1\n",
            "I Initializing variable: learning_rate\n",
            "I STARTING Optimization\n",
            "Epoch 0 |   Training | Elapsed Time: 0:46:35 | Steps: 159 | Loss: 61.435266     \n",
            "Epoch 0 | Validation | Elapsed Time: 0:06:01 | Steps: 45 | Loss: 34.083375 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "I Saved new best validating model with loss 34.083375 to: /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-732681\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 1 |   Training | Elapsed Time: 0:49:40 | Steps: 159 | Loss: 48.521804     \n",
            "Epoch 1 | Validation | Elapsed Time: 0:05:44 | Steps: 45 | Loss: 31.151135 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "I Saved new best validating model with loss 31.151135 to: /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-732840\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2 |   Training | Elapsed Time: 0:44:27 | Steps: 159 | Loss: 44.562250     \n",
            "Epoch 2 | Validation | Elapsed Time: 0:05:44 | Steps: 45 | Loss: 29.959502 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "I Saved new best validating model with loss 29.959502 to: /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-732999\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3 |   Training | Elapsed Time: 0:44:13 | Steps: 159 | Loss: 41.451331     \n",
            "Epoch 3 | Validation | Elapsed Time: 0:05:31 | Steps: 45 | Loss: 28.749540 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "I Saved new best validating model with loss 28.749540 to: /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-733158\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4 |   Training | Elapsed Time: 0:43:03 | Steps: 159 | Loss: 39.182191     \n",
            "Epoch 4 | Validation | Elapsed Time: 0:05:29 | Steps: 45 | Loss: 28.333168 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "I Saved new best validating model with loss 28.333168 to: /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-733317\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5 |   Training | Elapsed Time: 0:43:20 | Steps: 159 | Loss: 37.173287     \n",
            "Epoch 5 | Validation | Elapsed Time: 0:05:22 | Steps: 45 | Loss: 27.102798 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "I Saved new best validating model with loss 27.102798 to: /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-733476\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6 |   Training | Elapsed Time: 0:43:48 | Steps: 159 | Loss: 35.682210     \n",
            "Epoch 6 | Validation | Elapsed Time: 0:05:24 | Steps: 45 | Loss: 27.382433 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 7 |   Training | Elapsed Time: 0:23:03 | Steps: 159 | Loss: 34.457621     \n",
            "Epoch 7 | Validation | Elapsed Time: 0:00:11 | Steps: 45 | Loss: 26.317875 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "I Saved new best validating model with loss 26.317875 to: /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-733794\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 8 |   Training | Elapsed Time: 0:02:59 | Steps: 159 | Loss: 33.309533     \n",
            "Epoch 8 | Validation | Elapsed Time: 0:00:11 | Steps: 45 | Loss: 25.844261 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "I Saved new best validating model with loss 25.844261 to: /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-733953\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 9 |   Training | Elapsed Time: 0:03:00 | Steps: 159 | Loss: 32.363494     \n",
            "Epoch 9 | Validation | Elapsed Time: 0:00:11 | Steps: 45 | Loss: 25.574402 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "I Saved new best validating model with loss 25.574402 to: /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-734112\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 10 |   Training | Elapsed Time: 0:02:59 | Steps: 159 | Loss: 31.380244    \n",
            "Epoch 10 | Validation | Elapsed Time: 0:00:11 | Steps: 45 | Loss: 25.346596 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "I Saved new best validating model with loss 25.346596 to: /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-734271\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 11 |   Training | Elapsed Time: 0:02:58 | Steps: 159 | Loss: 30.851000    \n",
            "Epoch 11 | Validation | Elapsed Time: 0:00:11 | Steps: 45 | Loss: 25.019796 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "I Saved new best validating model with loss 25.019796 to: /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-734430\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 12 |   Training | Elapsed Time: 0:02:58 | Steps: 159 | Loss: 29.844732    \n",
            "Epoch 12 | Validation | Elapsed Time: 0:00:11 | Steps: 45 | Loss: 25.041536 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 13 |   Training | Elapsed Time: 0:02:57 | Steps: 159 | Loss: 29.129208    \n",
            "Epoch 13 | Validation | Elapsed Time: 0:00:11 | Steps: 45 | Loss: 24.515599 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "I Saved new best validating model with loss 24.515599 to: /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-734748\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 14 |   Training | Elapsed Time: 0:02:58 | Steps: 159 | Loss: 28.932119    \n",
            "Epoch 14 | Validation | Elapsed Time: 0:00:11 | Steps: 45 | Loss: 24.794260 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 15 |   Training | Elapsed Time: 0:02:58 | Steps: 159 | Loss: 28.301236    \n",
            "Epoch 15 | Validation | Elapsed Time: 0:00:11 | Steps: 45 | Loss: 24.568795 | Dataset: /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/dev.csv\n",
            "I Early stop triggered as the loss did not improve the last 2 epochs\n",
            "I FINISHED optimization in 6:44:22.060824\n",
            "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-734748\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "Testing model on /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test.csv\n",
            "Test epoch | Steps: 24 | Elapsed Time: 0:23:10                                  \n",
            "Test on /content/drive/MyDrive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test.csv - WER: 0.712126, CER: 0.166834, loss: 32.586063\n",
            "--------------------------------------------------------------------------------\n",
            "Best WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.000000, CER: 0.023256, loss: 10.028063\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/12-201007-230806_bem_526_elicit_25.wav\n",
            " - src: \"ukuipakisha  umunandi alwala mupepi ne mfwa\"\n",
            " - res: \"ukuipakisha umunandi alwala mupepi ne mfwa\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.000000, CER: 0.000000, loss: 7.333395\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/12-201007-175803_bem_526_elicit_4.wav\n",
            " - src: \"natuma no mwaice ukuyamupoka\"\n",
            " - res: \"natuma no mwaice ukuyamupoka\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.000000, CER: 0.000000, loss: 6.909759\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/12-201010-083232_bem_526_elicit_30.wav\n",
            " - src: \"namona akupukula amenso panono no kulanda nakalya\"\n",
            " - res: \"namona akupukula amenso panono no kulanda nakalya\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.000000, CER: 0.033333, loss: 6.421500\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/12-201007-230806_bem_526_elicit_26.wav\n",
            " - src: \"umunandi apola  ubwinga bwakwe\"\n",
            " - res: \"umunandi apola ubwinga bwakwe\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.000000, CER: 0.000000, loss: 5.962996\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/12-201008-123513_bem_526_elicit_45.wav\n",
            " - src: \"twabala twalatusha\"\n",
            " - res: \"twabala twalatusha\"\n",
            "--------------------------------------------------------------------------------\n",
            "Median WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.714286, CER: 0.116279, loss: 11.748388\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/12-201009-105041_bem_526_elicit_16.wav\n",
            " - src: \"nomba ine pa kumona ifyo campapusha nganshi\"\n",
            " - res: \"nomba ine pakumone efyo campakushanganshi\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.722222, CER: 0.189474, loss: 65.227097\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/06-200918-153816_bem_c20_elicit_33.wav\n",
            " - src: \"kalulu uko aali kumwakwa ati omfwe fi ati ine uko cikabile eko nja uko citalele nako eko nshili\"\n",
            " - res: \"kanu ukw ali kumwakwaat omfwa ifi ati ine ukwo cikabile eko ila okwacitalele nako ekomfhili\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.727273, CER: 0.231884, loss: 52.973602\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/06-200918-153816_bem_c20_elicit_6.wav\n",
            " - src: \"yaletifye nga akasuba kaba ku cungulo yaisa cilia yaikata umuntu yaya\"\n",
            " - res: \"yanetisenga akasuba kabakucububulo yaisa cilaaikatomunto yaya\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.727273, CER: 0.185185, loss: 51.693752\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/12-201010-100842_bem_526_elicit_31.wav\n",
            " - src: \"ilyo imfumu yapwile ukulondolola ifwe no mwenso walitwikete twatalele fye tondolo\"\n",
            " - res: \"ilyo fmuya kuya ukulondoloban ifwo no umwenso wali twikete twatalele fyo tondolo\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.727273, CER: 0.200000, loss: 47.658161\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/06-200918-153816_bem_c20_elicit_2.wav\n",
            " - src: \"imfumu ii yalifyele na umwana umwanakashi ishina lyakwe aali ni kasuba\"\n",
            " - res: \"imfumu iyalifyele naumwana bwanakase ishina lyakwe aleasuba\"\n",
            "--------------------------------------------------------------------------------\n",
            "Worst WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.500000, CER: 0.152174, loss: 19.959211\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/12-201007-230806_bem_526_elicit_17.wav\n",
            " - src: \"abapatili babwelelamo  amacushi yalanangulusha\"\n",
            " - res: \"aba pati li babwelelabu amacushi yalanango lusha\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.500000, CER: 0.222222, loss: 9.016271\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/12-201010-083232_bem_526_elicit_25.wav\n",
            " - src: \"ifyakucita fyabula\"\n",
            " - res: \"jifyaukuci ta ifyabula\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.500000, CER: 0.200000, loss: 7.369977\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/12-201010-081738_bem_526_elicit_8.wav\n",
            " - src: \"awe nabuca\"\n",
            " - res: \"awu na buca\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.500000, CER: 0.136364, loss: 6.807199\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/12-201009-111159_bem_526_elicit_32.wav\n",
            " - src: \"umunandi alanondolwela\"\n",
            " - res: \"umonandi ala nondoloela\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.600000, CER: 0.234043, loss: 37.190277\n",
            " - wav: file:///content/drive/My Drive/deepspeech/datastore_dir/deepspeech_dts/BembaSpeech/bembaspeech/test_/06-200916-110927_bem_c20_elicit_32.wav\n",
            " - src: \"mukwai kayabashintafye ukutali elyo kalabwelako\"\n",
            " - res: \"mukwai aya bashinsa fye ukuta ulo kala bwe ko\"\n",
            "--------------------------------------------------------------------------------\n",
            "I Exporting the model...\n",
            "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/finetune_model/checkpoint/deepspeech-0.8.2-checkpoint/best_dev-734748\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "I Models exported at /content/drive/MyDrive/deepspeech/finetune_model/export\n",
            "I Model metadata file saved to /content/drive/MyDrive/deepspeech/finetune_model/export/csikasote_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb2ISHPQaHah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53bf0c21-bdba-4160-ed75-5c51b77184db"
      },
      "source": [
        "# STEP 3: CREATE A MMAPABLE MODEL\n",
        "%cd '/content/DeepSpeech/'\n",
        "!python3 util/taskcluster.py \\\n",
        "  --source tensorflow \\\n",
        "  --artifact convert_graphdef_memmapped_format \\\n",
        "  --branch r1.15 \\\n",
        "  --target ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepSpeech\n",
            "Downloading https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.tensorflow.pip.r1.15.cpu/artifacts/public/convert_graphdef_memmapped_format ...\n",
            "Downloading: 100%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkhV-TiBN094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e2b643-7f01-488e-94a6-71d89bcb607c"
      },
      "source": [
        "%cd '/content/DeepSpeech/'\n",
        "!./convert_graphdef_memmapped_format \\\n",
        "  --in_graph='/content/drive/MyDrive/deepspeech/finetune_model/export/ft_model.pb' \\\n",
        "  --out_graph='/content/drive/MyDrive/deepspeech/finetune_model/export/ft_model.pbmm'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepSpeech\n",
            "2021-01-05 01:44:21.890866: I tensorflow/contrib/util/convert_graphdef_memmapped_format_lib.cc:171] Converted 7 nodes\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}